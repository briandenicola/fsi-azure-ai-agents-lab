{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Build a Search Agent\n",
    "\n",
    "In this lab, we'll use the Azure AI Agent Service to create an agent that is able to retrieve information from documents stored in Azure AI Search, a vector database. This pattern is known as retrieval augmented generation or RAG. The documents that we'll be searching are finance data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Create the Azure AI Search Index\n",
    "\n",
    "We'll start the lab by creating an Azure AI Search index, which will contain vectorized representations of our finance documents. The steps shown below to create the AI Search index are from the official Microsoft [documentation](https://learn.microsoft.com/en-us/azure/search/search-get-started-portal-import-vectors?tabs=sample-data-storage%2Cmodel-aoai%2Cconnect-data-storage)\n",
    "\n",
    "#### Step 1\n",
    "To begin, download the [documents](https://github.com/jakeatmsft/fsi-azure-ai-agents-lab/tree/main/labs/data) that we'll store in the Azure AI Search index.\n",
    "\n",
    "#### Step 2\n",
    "Next, we'll upload the data documents to Azure Blob Storage, which Azure AI search connects to.\n",
    "1. Navigate to your Storage Account (the one that was created automaticall during your AI Foundry project setup). \n",
    "2. Expand \"Data Storage\" in the side menu and click on \"Containers\". \n",
    "3. Create a new container named \"financedata\"\n",
    "\n",
    "\n",
    "4. Click into the new container and upload the documents you downloaded.\n",
    "\n",
    "#### Step 3\n",
    "We need an embedding model in order to convert our documents into vectors that will be stored in Azure AI Search...luckily, we've already deployed a  `text-embedding-3-large` model in Lab 1!\n",
    "\n",
    "#### Step 4\n",
    "Now we're ready to vectorize our documents.\n",
    "1. Go to your Azure AI Search Service where your  `text-embedding-3-large` model is deployed\n",
    "1. On the **Overview page**, select **Import and vectorize data**.\n",
    "1. On **Set up your data connection**, select **Azure Blob Storage**.\n",
    "1. Specify your subscription, storage account, and the container that contains your finance data. \n",
    "1. Make sure **Authenticate using managed idenity is checked** and the **Managed identity type** is set to **System-assigned**.\n",
    "\n",
    "5. On the **Vectorize your text** page, select **Azure OpenAI** for **Kind**, select your subscription, and select the name of your Azure OpenAI Service.\n",
    "6. For the **Model deployment** select `text-embedding-3-large`. \n",
    "7. The **Authentication type** should be set to **System-assigned identity**. \n",
    "8. Select the box next to the acknowledgement.\n",
    "\n",
    "    \n",
    "9. You can hit **Next** for the next two pages. When you get to the **Review and create** page, set **Objects name prefix** to **financedata-index**. \n",
    "10. Click **Create**. This will start the document indexing process which will vectorize your documents and create an index.\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import AzureAISearchTool\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationAgent:\n",
    "    \"\"\"\n",
    "    A class to represent the Validation Agent.\n",
    "    \"\"\"\n",
    "    @kernel_function(description='An agent that runs validation checks to ensure that the generated analyst report meets required standards.')\n",
    "    def validate_report(self, report: str) -> str:\n",
    "        \"\"\"\n",
    "        Validates the generated analyst report.\n",
    "        Requirement: The report must include a detailed risk assessment.\n",
    "        \n",
    "        Parameters:\n",
    "        report (str): The analyst report produced by the AnalystReportAgent.\n",
    "        \n",
    "        Returns:\n",
    "        last_msg (json): The final message containing the validation result.\n",
    "        \"\"\"\n",
    "        print(\"Calling ValidationAgent...\")\n",
    "        \n",
    "        project_client = AIProjectClient.from_connection_string(\n",
    "            credential=DefaultAzureCredential(),\n",
    "            conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"],\n",
    "        )\n",
    "        \n",
    "        validation_agent = project_client.agents.create_agent(\n",
    "            model=\"gpt-4o\",\n",
    "            name=\"validation-agent\",\n",
    "            instructions=\"You are an expert agent that validates analyst reports. Return 'Pass' if the report includes a detailed risk assessment and meets all reporting standards, otherwise return 'Fail'. You must only return 'Pass' or 'Fail'.\",\n",
    "        )\n",
    "        \n",
    "        thread = project_client.agents.create_thread()\n",
    "        \n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=f\"Validate that the generated analyst report includes a detailed risk assessment. Here is the report: {report}\",\n",
    "        )\n",
    "        \n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=validation_agent.id)\n",
    "        \n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "        \n",
    "        project_client.agents.delete_agent(validation_agent.id)\n",
    "        \n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        last_msg = messages.get_last_text_message_by_role(\"assistant\")\n",
    "        \n",
    "        print(\"ValidationAgent completed successfully.\")\n",
    "        return last_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Create the Search Agent\n",
    "\n",
    "Now that we've vectorized our documents and created an index, we can create a Search Agent that will retreive information about our data from the index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import AzureAISearchTool\n",
    "\n",
    "load_dotenv() # Loads the environment variables and credentials we need to setup the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Connect to your Azure AI Foundry project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to our Azure AI Foundry project, which will allow us to use the deployed gpt-4o model\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Connect to your Azure AI Search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection ID: /subscriptions/6025ba02-1dfd-407f-b358-88f811c7c7aa/resourceGroups/aigent_eus/providers/Microsoft.MachineLearningServices/workspaces/project-demo-ibnm/connections/hub-demo-ibnm-connection-AISearch\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the connections in your project and get the connection ID of the Aazure AI Search connection.\n",
    "conn_list = project_client.connections.list()\n",
    "conn_id = \"\"\n",
    "for conn in conn_list:\n",
    "    if conn.connection_type == \"CognitiveSearch\":\n",
    "        conn_id = conn.id\n",
    "        print(f\"Connection ID: {conn.id}\")\n",
    "\n",
    "# Connect to your Azure AI Search index\n",
    "ai_search = AzureAISearchTool(index_connection_id=conn_id, index_name=\"vector-1743105228180\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Define the search agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = project_client.agents.create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    name=\"search-agent\",\n",
    "    instructions=\"You are a helpful agent that is an expert at searching documents.\",\n",
    "    tools=ai_search.definitions,\n",
    "    tool_resources=ai_search.resources,\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Chat with the search agent\n",
    "\n",
    "Let's test our search agent by asking it to give us information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: The Velo product is listed as part of various business segments, including government and enterprise sectors. It appears in multiple countries such as the United States, Germany, Canada, France, and Mexico with different pricing and product configurations categorized by levels such as \"Low,\" \"Medium,\" and \"High.\" The Velo product is priced at $120.00 and is associated with different transaction structures, indicating a flexible pricing model depending on the sector and specific configuration【3†source】. \\n\n",
      "\n",
      "{'type': 'text', 'text': {'value': 'The Velo product is listed as part of various business segments, including government and enterprise sectors. It appears in multiple countries such as the United States, Germany, Canada, France, and Mexico with different pricing and product configurations categorized by levels such as \"Low,\" \"Medium,\" and \"High.\" The Velo product is priced at $120.00 and is associated with different transaction structures, indicating a flexible pricing model depending on the sector and specific configuration【3†source】.', 'annotations': [{'type': 'url_citation', 'text': '【3†source】', 'start_index': 496, 'end_index': 506, 'url_citation': {'url': 'financial_sample.xlsx', 'title': 'financial_sample.xlsx'}}]}}\n"
     ]
    }
   ],
   "source": [
    "# The name of the product we want to search for\n",
    "product_name = 'Velo'\n",
    "\n",
    "\n",
    "# Create a thread which is a conversation session between an agent and a user. \n",
    "thread = project_client.agents.create_thread()\n",
    "\n",
    "# Create a message in the thread with the user asking for information about a specific product\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=f\"Tell me about the {product_name} product.\", # The user's message\n",
    ")\n",
    "# Run the agent to process tne message in the thread\n",
    "run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=search_agent.id)\n",
    "\n",
    "# Check if the run was successful\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Delete the agent when it's done running\n",
    "#project_client.agents.delete_agent(search_agent.id)\n",
    "\n",
    "# Fetch all the messages from the thread\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "\n",
    "# Get the last message, which is the agent's resposne to the user's question\n",
    "last_msg = messages.get_last_text_message_by_role(\"assistant\")\n",
    "\n",
    "# Display the agent's response\n",
    "print('Agent:', last_msg.text.value, '\\n')\n",
    "print(last_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
