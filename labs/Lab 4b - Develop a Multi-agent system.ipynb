{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Develop a Finance Analyst Multi-Agent System\n",
    "\n",
    "In this lab, we’ll build a multi-agent system where a team of agents works together to generate detailed analyst reports about corporate finance data. The system consists of three task agents plus an orchestrator:\n",
    "\n",
    "1. FinanceDataAgent – This agent searches an Azure AI Search index to retrieve recent financial information and performance data for your company.\n",
    "2. AnalystReportAgent – This agent writes a detailed analyst report synthesizing the retrieved data, including insights on financial performance, Finance trends, and risk analysis.\n",
    "3. ValidationAgent – This agent validates that the final report includes a detailed risk assessment.\n",
    "4. FinanceOrchestratorAgent – The orchestrator that communicates with the above agents to create the final analyst report.\n",
    "\n",
    "We use the Azure AI Agent Service for the individual task agents and Semantic Kernel to build the orchestrator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Create the FinanceData, AnalystReport, and Validation Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import AzureAISearchTool\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create the FinanceDataAgent\n",
    "\n",
    "This agent from Lab 2a searches your existing vector store retrieves relevant financial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from lida import Manager, TextGenerationConfig\n",
    "from llmx import llm, TextGenerationConfig\n",
    "import os\n",
    "from typing import Set, Callable, Dict, Any, List, Optional\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Azure and telemetry imports\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    AsyncFunctionTool, \n",
    "    RequiredFunctionToolCall, \n",
    "    SubmitToolOutputsAction, \n",
    "    ToolOutput, \n",
    "    AsyncToolSet,\n",
    "    CodeInterpreterTool,\n",
    "    BingGroundingTool\n",
    ")\n",
    "from azure.ai.projects.telemetry.agents import AIAgentsInstrumentor\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry import trace\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def fetch_current_datetime(format: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Get the current time as a JSON string, optionally formatted.\n",
    "\n",
    "    :param format (Optional[str]): The format in which to return the current time. Defaults to None.\n",
    "    :return: The current time in JSON format.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    # Use the provided format if available, else use a default format\n",
    "    if format:\n",
    "        time_format = format\n",
    "    else:\n",
    "        time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "    time_json = json.dumps({\"current_time\": current_time.strftime(time_format)})\n",
    "    return time_json\n",
    "\n",
    "async def generate_analysis(question: str,model_deployment:str, data_input: str, output_folder:str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a summary and visualize the data based on the question.\n",
    "\n",
    "    :param question (str): The analysis question.\n",
    "    :param data_input (str): The data to analyze.\n",
    "    :return: Path to the saved chart image or an error message.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # Initialize LLM with Azure OpenAI\n",
    "    text_gen = llm(\n",
    "    provider=\"openai\",\n",
    "    api_type=\"azure\",\n",
    "    azure_endpoint=os.environ.get(\"CHAT_MODEL_ENDPOINT\"),\n",
    "    api_key=os.environ.get(\"CHAT_MODEL_API_KEY\"),\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "        )\n",
    "        # Load the Excel File into a DataFrame\n",
    "    df = pd.read_excel(data_input)\n",
    "    print(f\"Workbook '{data_input}' successfully loaded.\")\n",
    "\n",
    "    lida = Manager(text_gen=text_gen)\n",
    "\n",
    "    # Configure text generation\n",
    "    textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=model_deployment, use_cache=False)\n",
    "\n",
    "    # Summarize the input data\n",
    "    summary = lida.summarize(df, summary_method=\"default\", textgen_config=textgen_config)  \n",
    "\n",
    "    # Visualize the summary based on the question\n",
    "    charts = lida.visualize(summary=summary, goal=question, textgen_config=textgen_config)  \n",
    "\n",
    "    if len(charts) > 0:\n",
    "        chart = charts[0]\n",
    "        code = chart.code\n",
    "\n",
    "        # Create a timestamp for saving files\n",
    "        run_timestamp = str(int(time.time()))\n",
    "        \n",
    "        #create output folder if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # Save summary to a Python file\n",
    "        #with open(f'{output_folder}/summary_{run_timestamp}.py', 'w') as f:\n",
    "        #    f.write(str(summary))\n",
    "        \n",
    "        # Save generated code to a Python file\n",
    "        with open(f'{output_folder}/code_{run_timestamp}.py', 'w') as f:\n",
    "            f.write(code)\n",
    "        \n",
    "        # Save the chart image\n",
    "        chart.savefig(f'{output_folder}/chart_{run_timestamp}.png')\n",
    "\n",
    "        return f'{output_folder}/chart_{run_timestamp}.png'\n",
    "    else:\n",
    "        field_list = str(summary['field_names'])\n",
    "        return f\"Unable to visualize question, please try again with these fields: {field_list}\"\n",
    "    \n",
    "async def visual_analysis(question: str, img_path: str, deployment_model:str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze the chart image and provide detailed insights.\n",
    "\n",
    "    :param question (str): The analysis question.\n",
    "    :param img_path (str): Path to the chart image.\n",
    "    :return: Detailed analysis in JSON format.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # Initialize Azure OpenAI client\n",
    "    client = AzureOpenAI(  \n",
    "        azure_endpoint=os.environ.get(\"CHAT_MODEL_ENDPOINT\"),\n",
    "        api_key=os.environ.get(\"CHAT_MODEL_API_KEY\"),\n",
    "        api_version=\"2024-05-01-preview\",  \n",
    "    )  \n",
    "\n",
    "    # Read and encode the image\n",
    "    with open(img_path, 'rb') as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('ascii')\n",
    "\n",
    "    # Define the chat prompt\n",
    "    chat_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"\"\"Please analyze the image and provide a detailed analysis of the chart for this question,\n",
    "                      : {question}, in addition include markdown representation of the data in the image\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ] \n",
    "    \n",
    "    # Include speech result if speech is enabled  \n",
    "    messages = chat_prompt  \n",
    "        \n",
    "    # Generate the completion  \n",
    "    completion = client.chat.completions.create(  \n",
    "        model=deployment_model,\n",
    "        messages=messages,\n",
    "        max_tokens=800,  \n",
    "        temperature=0,  \n",
    "        top_p=0.95,  \n",
    "        frequency_penalty=0,  \n",
    "        presence_penalty=0,\n",
    "        stop=None,  \n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return completion.to_json()  \n",
    "        \n",
    "\n",
    "# Statically defined user functions for fast reference with send_email as async but the rest as sync\n",
    "user_async_function_tools: Set[Callable[..., Any]] = {\n",
    "    generate_analysis,\n",
    "    visual_analysis\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c8cd181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FinanceDataScientistAgent:\n",
    "    \"\"\"\n",
    "    A class to represent the Finance Data Agent.\n",
    "    \"\"\"\n",
    "    # def __init__(self, data_input, model_deployment, output_folder):\n",
    "    #     self.data_input = data_input\n",
    "    #     self.model_deployment = model_deployment\n",
    "    #     self.output_folder = output_folder\n",
    "\n",
    "    @kernel_function(description='An agent that analyzes financial information from internal data.')\n",
    "    async def search_finance_data(self, question: str) -> str:\n",
    "        async with DefaultAzureCredential() as creds:\n",
    "            async with AIProjectClient.from_connection_string(\n",
    "                credential=creds, conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"],\n",
    "            ) as project_client:\n",
    "                model_deployment = os.environ[\"CHAT_MODEL\"]\n",
    "                data_input=\"./data/financial_sample.xlsx\"\n",
    "                output_folder= \"output\"\n",
    "                # Configure Azure Monitor for telemetry\n",
    "                application_insights_connection_string = await project_client.telemetry.get_connection_string()\n",
    "                configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "                \n",
    "                # Initialize assistant functions\n",
    "                functions = AsyncFunctionTool(functions=user_async_function_tools)\n",
    "                code_interpreter = CodeInterpreterTool()\n",
    "\n",
    "                # Setup toolset\n",
    "                toolset = AsyncToolSet()\n",
    "                toolset.add(functions)\n",
    "                # Uncomment the next line if you want to add the code interpreter\n",
    "                # toolset.add(code_interpreter)\n",
    "\n",
    "                agent_name = \"data-science-assistant\"\n",
    "\n",
    "                # Check if the agent already exists\n",
    "                agents = await project_client.agents.list_agents()\n",
    "                agent = next((a for a in agents.data if a.name == agent_name), None)\n",
    "\n",
    "                if agent is None:\n",
    "                    # Create a new agent if not found\n",
    "                    agent = await project_client.agents.create_agent(\n",
    "                        model=model_deployment,\n",
    "                        name=agent_name,\n",
    "                        instructions=(\n",
    "                            'You are a data scientist with access to a tool called generate_analysis '\n",
    "                            'which can perform analysis and save results for you. Use the data_input provided. '\n",
    "                            'Use the generate_analysis tool to answer the question, then use the visual_analysis '\n",
    "                            'to process the image. The answer should be no greater than 1000 characters in length.'\n",
    "                        ),\n",
    "                        tools=functions.definitions #+ code_interpreter.definitions\n",
    "                    )\n",
    "                    print(f\"Created agent, agent ID: {agent.id}\")\n",
    "                else:\n",
    "                    print(f\"Found existing agent: {agent.id}\")\n",
    "\n",
    "                # Create a thread for communication\n",
    "                thread = await project_client.agents.create_thread()\n",
    "                print(f\"Created thread, ID: {thread.id}\")\n",
    "                \n",
    "                # Send a message to the agent\n",
    "                message = await project_client.agents.create_message(\n",
    "                    thread_id=thread.id, \n",
    "                    role=\"user\", \n",
    "                    content=f\"Current date is {datetime.datetime.now().strftime('%Y-%m-%d')}.model_deployment:{model_deployment}, {question},output_folder:{output_folder}, data_input:{data_input}\"\n",
    "                )\n",
    "                print(f\"Created message, ID: {message.id}\")\n",
    "\n",
    "                # Process the agent run with the provided tools\n",
    "                run = await project_client.agents.create_and_process_run(\n",
    "                    thread_id=thread.id, \n",
    "                    agent_id=agent.id, \n",
    "                    toolset=toolset\n",
    "                )\n",
    "                print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "                if run.status == \"failed\":\n",
    "                    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "                print(f\"Run completed with status: {run.status}\")\n",
    "\n",
    "                # Fetch and log all messages from the thread\n",
    "                messages = await project_client.agents.list_messages(thread_id=thread.id)\n",
    "                print(f\"Messages: {messages}\")\n",
    "\n",
    "                # Save any generated files (e.g., images)\n",
    "                for file_path_annotation in messages.file_path_annotations:\n",
    "                    print(f\"File Paths:\")\n",
    "                    print(f\"Type: {file_path_annotation.type}\")\n",
    "                    print(f\"Text: {file_path_annotation.text}\")\n",
    "                    print(f\"File ID: {file_path_annotation.file_path.file_id}\")\n",
    "                    print(f\"Start Index: {file_path_annotation.start_index}\")\n",
    "                    print(f\"End Index: {file_path_annotation.end_index}\")\n",
    "                    file_name = Path(file_path_annotation.text).name\n",
    "                    await project_client.agents.save_file(\n",
    "                        file_id=file_path_annotation.file_path.file_id, \n",
    "                        file_name=file_name\n",
    "                    )\n",
    "                    print(f\"Saved image file to: {Path.cwd() / file_name}\")\n",
    "\n",
    "                await project_client.agents.delete_agent(agent.id)\n",
    "\n",
    "                # Get the last message from the conversation\n",
    "                last_message = messages.text_messages[0].text\n",
    "                response = last_message\n",
    "                return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb8492",
   "metadata": {},
   "source": [
    "#### Step 3: Create the AnalystReportAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cf6db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalystReportAgent:\n",
    "    \"\"\"\n",
    "    A class to represent the Analyst Report Agent.\n",
    "    \"\"\"\n",
    "    @kernel_function(description='An agent that writes detailed analyst reports on finance data.')\n",
    "    async def write_report(self, finance_data:str, data_description: str) -> str:\n",
    "        \"\"\"\n",
    "        Writes a detailed analyst report for a company.\n",
    "        \n",
    "        Parameters:\n",
    "        finance_data (str): the financial data to be included in the report.\n",
    "        data_description (str): the topic of the report.\n",
    "\n",
    "        Returns:\n",
    "        last_msg (json): The final message containing the detailed analyst report.\n",
    "        \"\"\"\n",
    "        print(\"Calling AnalystReportAgent...\")\n",
    "        \n",
    "        project_client = AIProjectClient.from_connection_string(\n",
    "            credential=DefaultAzureCredential(),\n",
    "            conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"],\n",
    "        )\n",
    "        \n",
    "        report_agent = await project_client.agents.create_agent(\n",
    "            model=\"gpt-4o\",\n",
    "            name=\"analyst-report-agent\",\n",
    "            instructions=\"You are a helpful agent specializing in writing comprehensive analyst reports. Your report should include full analysis of the data.\",\n",
    "        )\n",
    "        \n",
    "        thread = await project_client.agents.create_thread()\n",
    "        \n",
    "        message = await project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=f\"Write a detailed analyst report regarding {data_description}. Include insights provided by the {finance_data}.\",\n",
    "        )\n",
    "        \n",
    "        run = await project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=report_agent.id)\n",
    "        \n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "        \n",
    "        await project_client.agents.delete_agent(report_agent.id)\n",
    "        \n",
    "        messages =await project_client.agents.list_messages(thread_id=thread.id)\n",
    "        last_msg = messages.get_last_text_message_by_role(\"assistant\")\n",
    "        \n",
    "        print(\"AnalystReportAgent completed successfully.\")\n",
    "        return last_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d743fcb",
   "metadata": {},
   "source": [
    "#### Step 4: Create the Validation Agent\n",
    "\n",
    "This agent validates that the generated analyst report meets our standards – specifically, it checks that the report includes a detailed risk assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "145d744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationAgent:\n",
    "    \"\"\"\n",
    "    A class to represent the Validation Agent.\n",
    "    \"\"\"\n",
    "    @kernel_function(description='An agent that runs validation checks to ensure that the generated analyst report meets required standards.')\n",
    "    async def validate_report(self, report: str) -> str:\n",
    "        \"\"\"\n",
    "        Validates the generated analyst report.\n",
    "        Requirement: The report must include a detailed risk assessment.\n",
    "        \n",
    "        Parameters:\n",
    "        report (str): The analyst report produced by the AnalystReportAgent.\n",
    "        \n",
    "        Returns:\n",
    "        last_msg (json): The final message containing the validation result.\n",
    "        \"\"\"\n",
    "        print(\"Calling ValidationAgent...\")\n",
    "        \n",
    "        project_client = AIProjectClient.from_connection_string(\n",
    "            credential=DefaultAzureCredential(),\n",
    "            conn_str=os.environ[\"AIPROJECT_CONNECTION_STRING\"],\n",
    "        )\n",
    "        \n",
    "        validation_agent = await project_client.agents.create_agent(\n",
    "            model=\"gpt-4o\",\n",
    "            name=\"validation-agent\",\n",
    "            instructions=\"You are an expert agent that validates analyst reports. Return 'Pass' if the report includes a detailed assessment, otherwise return 'Fail'. You must only return 'Pass' or 'Fail'.\",\n",
    "        )\n",
    "        \n",
    "        thread = await project_client.agents.create_thread()\n",
    "        \n",
    "        message = await project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=f\"Validate that the generated analyst report includes a detailed assessment of data. Here is the report: {report}\",\n",
    "        )\n",
    "        \n",
    "        run = await project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=validation_agent.id)\n",
    "        \n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "        \n",
    "        await project_client.agents.delete_agent(validation_agent.id)\n",
    "        \n",
    "        messages = await project_client.agents.list_messages(thread_id=thread.id)\n",
    "        last_msg = messages.get_last_text_message_by_role(\"assistant\")\n",
    "        \n",
    "        print(\"ValidationAgent completed successfully.\")\n",
    "        return last_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1876f7f",
   "metadata": {},
   "source": [
    "### Part 2: Create a Multi-Agent System for Generating Analyst Reports\n",
    "\n",
    "The orchestrator (FinanceOrchestratorAgent) will coordinate the above agents to generate an analyst report. When you run the notebook, you will be prompted for a publicly traded company name. If the generated report meets the validation criteria, it will be saved as a file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40712164",
   "metadata": {},
   "source": [
    "Try the following prompts:\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ed487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinanceOrchestratorAgent is starting...\n",
      "Created agent, agent ID: asst_a1NtKF1axI8XdnL1k3mADbsz\n",
      "Created thread, ID: thread_kd4rGs8WL5DFabX2kWFR5mVW\n",
      "Created message, ID: msg_Ofyk9eDsxTcip3LfFZklj4Fk\n",
      "Workbook './data/financial_sample.xlsx' successfully loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:17: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED\n",
      "Run completed with status: RunStatus.COMPLETED\n",
      "Messages: {'object': 'list', 'data': [{'id': 'msg_oJ46NuqKIl3DtigXHoF1ND0M', 'object': 'thread.message', 'created_at': 1743196405, 'assistant_id': 'asst_a1NtKF1axI8XdnL1k3mADbsz', 'thread_id': 'thread_kd4rGs8WL5DFabX2kWFR5mVW', 'run_id': 'run_6Z3E99D5GiFtLwzWpV27GeC5', 'role': 'assistant', 'content': [{'type': 'text', 'text': {'value': 'The financial data for the Velo product across five countries—Mexico, France, Germany, United States, and Canada—shows a consistent profit margin despite variations in gross sales and COGS. Germany and the USA lead in gross sales with approximately 200,000 each, followed by France, Canada, and Mexico. Discounts are uniformly around 10,000 across countries, leading to sales figures proportional to gross sales. COGS vary by country, indicating effective cost management. The profit margin remains at roughly 25,000 for all, suggesting solid pricing and expense strategies. This analysis highlights cost efficiency and market performance, with Germany and USA demonstrating higher sales levels while maintaining consistent profits.', 'annotations': []}}], 'attachments': [], 'metadata': {}}, {'id': 'msg_Ofyk9eDsxTcip3LfFZklj4Fk', 'object': 'thread.message', 'created_at': 1743196376, 'assistant_id': None, 'thread_id': 'thread_kd4rGs8WL5DFabX2kWFR5mVW', 'run_id': None, 'role': 'user', 'content': [{'type': 'text', 'text': {'value': 'Current date is 2025-03-28.model_deployment:gpt-4o, Provide financial data for the Velo product across all countries and segments.,output_folder:output, data_input:./data/financial_sample.xlsx', 'annotations': []}}], 'attachments': [], 'metadata': {}}], 'first_id': 'msg_oJ46NuqKIl3DtigXHoF1ND0M', 'last_id': 'msg_Ofyk9eDsxTcip3LfFZklj4Fk', 'has_more': False}\n",
      "Calling AnalystReportAgent...\n",
      "AnalystReportAgent completed successfully.\n",
      "Calling ValidationAgent...\n",
      "ValidationAgent completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Environment variables to connect to the gpt-4o model\n",
    "deployment_name = os.environ[\"CHAT_MODEL\"]\n",
    "endpoint = os.environ[\"CHAT_MODEL_ENDPOINT\"]\n",
    "api_key = os.environ[\"CHAT_MODEL_API_KEY\"]\n",
    "output_folder = \"output\"\n",
    "\n",
    "async def main():\n",
    "    # Initialize the Semantic Kernel.\n",
    "    kernel = Kernel()\n",
    "    \n",
    "    # Add services and plugins to the kernel.\n",
    "    service_id = \"orchestrator_agent\"\n",
    "    kernel.add_service(AzureChatCompletion(service_id=service_id, deployment_name=deployment_name, endpoint=endpoint, api_key=api_key))\n",
    "    kernel.add_plugin(AnalystReportAgent(), plugin_name=\"AnalystReportAgent\")\n",
    "    kernel.add_plugin(FinanceDataScientistAgent(), plugin_name=\"FinanceDataScientistAgent\")\n",
    "    kernel.add_plugin(ValidationAgent(), plugin_name=\"ValidationAgent\")\n",
    "    \n",
    "    settings = kernel.get_prompt_execution_settings_from_service_id(service_id=service_id)\n",
    "    settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "    \n",
    "    # Create the FinanceOrchestratorAgent to coordinate the agents.\n",
    "    agent = ChatCompletionAgent(\n",
    "        service_id=\"orchestrator_agent\",\n",
    "        kernel=kernel,\n",
    "        name=\"FinanceOrchestratorAgent\",\n",
    "        instructions=f\"\"\"\n",
    "        You are an agent designed to create detailed analyst reports for finance data. The user will provide a data_description, and you will generate an analyst report by orchestrating the plugin agents:\n",
    "        \n",
    "        - AnalystReportAgent: Formats finance data into report, writes comprehensive analyst reports.\n",
    "        - FinanceDataScientistAgent: Retrieves financial data and Finance performance information.\n",
    "        - ValidationAgent: Checks that the report includes a detailed risk assessment.\n",
    "        \n",
    "        It is crucial that the final report includes a risk assessment section. If the report does not meet this requirement, it should be rejected.\n",
    "        Format your final response as a JSON object with two attributes, report_was_generated and content:\n",
    "        \n",
    "        - report_was_generated: Boolean that is true if a valid report was produced, otherwise false.\n",
    "        - content: A string containing the source finance data from the FinanceDataAgent and detailed analyst report if valid, or an error message if not.\n",
    "        \n",
    "        Example response:\n",
    "        {{\"report_was_generated\": false, \"content\": \"The analyst report for the requested company could not be generated because it lacks a risk assessment section.\"}}\n",
    "        \n",
    "        Your response must be a single valid JSON object using lowercase booleans (true/false) and double quotes for all keys and string values.\n",
    "        \"\"\",\n",
    "        execution_settings=settings,\n",
    "    )\n",
    "    \n",
    "    history = ChatHistory()\n",
    "    \n",
    "    is_complete = False\n",
    "    while not is_complete:\n",
    "        print(\"FinanceOrchestratorAgent is starting...\")\n",
    "        \n",
    "        user_input = input(\"Hello. Please provide the description to generate an analyst report. Type 'exit' to end the conversation: \")\n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            is_complete = True\n",
    "            break\n",
    "        \n",
    "        history.add_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "        \n",
    "        async for response in agent.invoke(history=history):\n",
    "            fixed_content = response.content.replace(\"False\", \"false\").replace(\"True\", \"true\")\n",
    "            print(f\"Response: {fixed_content}\")\n",
    "            response_json = json.loads(fixed_content)\n",
    "            report_was_generated = response_json['report_was_generated']\n",
    "            report_content = response_json['content']\n",
    "            \n",
    "            if report_was_generated:\n",
    "                report_name = f\"Analyst Report - {user_input}.md\"\n",
    "\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "                with open(f\"{output_folder}/{report_name}\".format(report_name), \"w\") as f:\n",
    "                    f.write(report_content)\n",
    "                print(f\"The analyst report for {user_input} has been generated. Please check the file {report_name}.\")\n",
    "            else:\n",
    "                print(report_content)\n",
    "                \n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7f505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
